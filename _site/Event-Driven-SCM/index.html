<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>Event-Driven Supply Chain for Crisis with FlinkSQL | Data Crafts</title>

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Event-Driven Supply Chain for Crisis with FlinkSQL | Data Crafts</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Event-Driven Supply Chain for Crisis with FlinkSQL" />
<meta name="author" content="abdelkrim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How Open Source Streaming technologies can help improve supply chain during Covid-19" />
<meta property="og:description" content="How Open Source Streaming technologies can help improve supply chain during Covid-19" />
<link rel="canonical" href="http://localhost:4000/Event-Driven-SCM/" />
<meta property="og:url" content="http://localhost:4000/Event-Driven-SCM/" />
<meta property="og:site_name" content="Data Crafts" />
<meta property="og:image" content="http://localhost:4000/assets/images/1-1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-12T00:00:00+02:00" />
<script type="application/ld+json">
{"image":"http://localhost:4000/assets/images/1-1.jpg","author":{"@type":"Person","name":"abdelkrim"},"description":"How Open Source Streaming technologies can help improve supply chain during Covid-19","headline":"Event-Driven Supply Chain for Crisis with FlinkSQL","dateModified":"2020-04-12T00:00:00+02:00","datePublished":"2020-04-12T00:00:00+02:00","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"abdelkrim"},"url":"http://localhost:4000/Event-Driven-SCM/","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/Event-Driven-SCM/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Data Crafts">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>
		  
                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Data Crafts</h1>
    <p class="lead">
        Welcome to Data Crafts' blog.
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Event-Driven Supply Chain for Crisis with FlinkSQL&url=http://localhost:4000/Event-Driven-SCM/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/Event-Driven-SCM/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Event-Driven-SCM/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="https://www.gravatar.com/avatar/22d66e5933a43f7422aff47bd2ef84e2?s=250&d=mm&r=x" alt="Abdelkrim">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://www.datacrafts.fr/about">Abdelkrim</a><a target="_blank" href="https://twitter.com/ahadjidj" class="btn follow">Follow</a>
                        <span class="author-description">Data Streaming Specialist at Cloudera | Mentor | Speaker | Teacher | I write about distributed systems, solution engineering and craftmanship </span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Event-Driven Supply Chain for Crisis with FlinkSQL</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid" src="/assets/images/1-1.jpg" alt="Event-Driven Supply Chain for Crisis with FlinkSQL">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#how-is-supply-chain-challenged">How is Supply Chain challenged?</a></li>
  <li><a href="#an-open-source-event-driven-retail-supply-chain">An Open Source Event-Driven Retail Supply Chain</a></li>
  <li><a href="#data-model-and-ingestion">Data model and ingestion</a></li>
  <li><a href="#data-exploration-with-flink-sql-and-zeppelin">Data exploration with Flink SQL and Zeppelin</a>
    <ul>
      <li><a href="#what-do-we-have-in-hands">What do we have in hands?</a></li>
      <li><a href="#stream-to-stream-joins-and-enrichment">Stream to Stream Joins and enrichment</a></li>
      <li><a href="#detect-products-running-out-fast">Detect products running out fast</a></li>
    </ul>
  </li>
  <li><a href="#creating-a-new-alerts-stream">Creating a new alerts stream</a></li>
  <li><a href="#conclusions">Conclusions</a></li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <p>Technology is helping the world survive through the sanitary, economical and societal crisis that the Covid19 virus has caused. AI helps scientists understand the virus to find a cure/vaccine. Mobile apps keep families and friends connected from afar. IoT is used to manage the virus spread through Bluetooth peer-to-peer interactions. More examples of how technology is helping are laid out in many blog posts. In this blog post, I focus on how Streaming technology can help supply chains during the crisis.</p>

<h2 id="how-is-supply-chain-challenged">How is Supply Chain challenged?</h2>

<p>A picture is worth a thousand words. Above is a picture I took in a Parisian store just few days before announcing the lock-down. Scary, right? Under anxiety, people started stocking up food although the CPG industry had announced there would be no shortages. This behavior created temporary shortages which scared people and hindered their trust in the official information. They started stocking up themselves, making the situation worse. Vicious circle.</p>

<p>Retail is just an example that is well known to the public. Hospitals Supply Chain challenges are much bigger. The exponential number of Covid19 cases creates a continuous stress on test kits, personal protective equipment, drugs, ICU beds, ventilators and staff. In France, patients are moved between cities with medical trains and flights. Some of them are taken care of in Germany. Airlines are helping in cargo activities moving millions of masks from China. Every decision needs to be taken fast with many unknowns, and can impact people’s lives.</p>

<blockquote>
  <p>But with big challenges come big opportunities.</p>
</blockquote>

<p>With IoT and a Streaming Platform, we get a real-time view on stocks and demand across a whole provider, country or even an industry. We can instantly trigger alerts when stocks are running out faster because of unexpected demand. Actions can be prioritized, decisions become backed by data, they can be made quickly to adapt to changing patterns. Furthermore, this platform helps gather more data hence making predictions more accurate.</p>

<h2 id="an-open-source-event-driven-retail-supply-chain">An Open Source Event-Driven Retail Supply Chain</h2>

<p>To get practical, let’s see how we can implement this vision with the Open Source software available in <a href="https://www.cloudera.com/products/cloudera-data-platform.html">Cloudera Data Platform</a> and <a href="https://www.cloudera.com/products/cdf.html">Cloudera Data Flow</a>. The architecture uses:</p>

<ol>
  <li><a href="https://nifi.apache.org/minifi/">MiNiFi</a>: small data collection agents are deployed in every Point Of Sales (POS) to collect sales transactions and send them in real time to the data center or the cloud.</li>
  <li><a href="https://nifi.apache.org/index.html">Apache NiFi</a>: collects sales events coming from the agents and send them to the <a href="https://kafka.apache.org">Apache Kafka</a> broker. NiFi also ingests data about stores and products from several DBs in realtime into Kafka.</li>
  <li><a href="https://flink.apache.org/">Apache Flink</a>: processes data coming from different Kafka topics to enrich POS events, aggregate them on time windows, detect threshold violations, etc. Apache Flink has an SQL API that make writing pipelines easier.</li>
  <li><a href="https://zeppelin.apache.org/">Apache Zeppelin</a>: is an interactive notebook that supports Apache Flink and Flink SQL for exploring data, building real-time dashboard and communicating information with different teams.</li>
  <li><a href="https://kafka.apache.org/documentation/#connect">Kafka Connect</a>: collects events from different topics and store them into a Cloud Storage like S3 or ADLS. Data is persisted on cheaper storage for long term archival or other batch use cases.</li>
  <li><a href="https://www.cloudera.com/products/machine-learning.html">Cloudera Machine Learning</a>: process data, train machine learning models, extract features and predict future patterns based on various set of data.</li>
</ol>

<p>In the coming sections, we will focus on the event streaming pipeline.</p>

<p><img src="/assets/images/1-2.png" alt="photo" /></p>

<h2 id="data-model-and-ingestion">Data model and ingestion</h2>

<p>I have covered NiFi and MiNiFi capabilities in several blogs. We can deploy thousands of small agents into stores and control them from a central location. Each agent can locally collect data from a data source at the store (a database, a file or a lightweight broker like MQTT) and send it to a central NiFi. For more information on this part, please refer to the detailed blog post I wrote about how to build an Industrial IoT system, then replace a factory by a store.</p>

<p><a href="https://medium.com/free-code-camp/building-an-iiot-system-using-apache-nifi-mqtt-and-raspberry-pi-ce1d6ed565bc" target="_blank"><img src="/assets/images/1-3.png" alt="photo" /></a></p>

<p>Once data is received in NiFi, we can publish events to Kafka with a simple flow. The below flow attach a schema name (pos) to each event, and push it to the pos Kafka topic.</p>

<p style="text-align: center;"><img src="/assets/images/1-4.png" alt="photo" class="center-image" /></p>

<p>Events coming from stores has the below attributes. This event means Store ‘5’ sold 3 items of Product ‘8’.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="p">{</span>
  <span class="s2">"tstx"</span> <span class="p">:</span> <span class="s2">"1586615062225"</span><span class="p">,</span> <span class="c1">//transaction timestamp</span>
  <span class="s2">"idtx"</span> <span class="p">:</span> <span class="s2">"1871134"</span><span class="p">,</span><span class="c1">// transaction identifier</span>
  <span class="s2">"idstore"</span> <span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="c1">// store identifier</span>
  <span class="s2">"idproduct"</span> <span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="c1">// product identifier</span>
  <span class="s2">"quantity"</span> <span class="p">:</span> <span class="mi">3</span> <span class="c1">// quantity at which the product was sold</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Similarly, NiFi can monitor several tables and incrementally ingest new or updated rows into Kafka. In our use case, we ingest data from a stores table that has details on every store such us name and location.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="p">{</span>
  <span class="s2">"idstore"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
  <span class="s2">"namestore"</span><span class="p">:</span><span class="s2">"supermarket"</span><span class="p">,</span>
  <span class="s2">"city"</span><span class="p">:</span><span class="s2">"paris"</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We also ingest data from a products table that has details on every product such us as product name and observed average sold quantity at a given frequency.</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="p">{</span>
  <span class="s2">"idproduct"</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span>
  <span class="s2">"nameproduct"</span><span class="p">:</span><span class="s2">"hand-sanitiser"</span><span class="p">,</span>
  <span class="s2">"avgsales"</span><span class="p">:</span><span class="mi">2</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The results of the data ingestion can be seen in the following video where I use Streams Messaging Manager to explore the content of the three Kafka topics : pos, stores and products. These topics are partitioned and events are distributed based on the id field to load balance the processing later. We have also prepared a forth topic, alerts, that we will use later to send alerts when we detect that a product is being sold faster than usual. From the video, you can also see the producers to and consumer from each topic.</p>

<iframe width="1120" height="680" src="https://www.youtube.com/embed/K2R4twlsRfM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="data-exploration-with-flink-sql-and-zeppelin">Data exploration with Flink SQL and Zeppelin</h2>

<p>Apache Flink is a modern, Open Source, streaming engine that we will use to build our data pipeline. Flink can be used for real-time ETL where events are transformed in real-time. It can also be used to compute advanced KPI based on different time manipulation (event time and processing time, windowing, statefull processing etc). Apache Flink has powerful APIs such as DataStream and ProcessFunction APIs that can be used to build modern event-driven applications. It also has easy-to-use Table and SQL API that democratize the technology to analyst users. We will leverage the SQL API to make this blog accessible to a wider community. To use Flink SQL, the out-of-the-box option is the SQL Client CLI. Let’s use it first to explore the content of the POS topic:</p>

<iframe width="1120" height="630" src="https://www.youtube.com/embed/87VocUvMBBc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The Flink SQL CLI is nice for simple analysis. However, it’s not convenient for data exploration where you want to test and adapt several queries. Fortunately, Apache Zeppelin, the datascience notebook, supports running Flink and Flink SQL code. We will use it in the coming sections. Let’s get started!</p>

<h3 id="what-do-we-have-in-hands">What do we have in hands?</h3>

<p>To process our streams in FlinkSQL, we need to create tables. A table define the schema of events in a Kafka topic and provide access to the SQL API. For instance, to create a table of our POS stream, we can use:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">pos</span> <span class="p">(</span>
   <span class="n">tstx</span> <span class="n">BIGINT</span><span class="p">,</span>
   <span class="n">idtx</span> <span class="n">BIGINT</span><span class="p">,</span>
   <span class="n">idstore</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">idproduct</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">quantity</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">timetx</span> <span class="k">AS</span> <span class="k">CAST</span><span class="p">(</span><span class="n">from_unixtime</span><span class="p">(</span><span class="n">floor</span><span class="p">(</span><span class="n">tstx</span><span class="o">/</span><span class="mi">1000</span><span class="p">))</span> <span class="k">AS</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">)),</span>
   <span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">timetx</span> <span class="k">AS</span> <span class="n">timetx</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'10'</span> <span class="k">SECOND</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
   <span class="s1">'connector.type'</span> <span class="o">=</span> <span class="s1">'kafka'</span><span class="p">,</span>
   <span class="s1">'connector.version'</span> <span class="o">=</span> <span class="s1">'universal'</span><span class="p">,</span>
   <span class="s1">'connector.topic'</span> <span class="o">=</span> <span class="s1">'pos'</span><span class="p">,</span>
   <span class="s1">'connector.startup-mode'</span> <span class="o">=</span> <span class="s1">'latest-offset'</span><span class="p">,</span>
   <span class="s1">'connector.properties.bootstrap.servers'</span> <span class="o">=</span> <span class="s1">'kafka-url:9092'</span><span class="p">,</span>
   <span class="s1">'connector.properties.group.id'</span> <span class="o">=</span> <span class="s1">'FlinkSQLPOS'</span><span class="p">,</span>
   <span class="s1">'format.type'</span> <span class="o">=</span> <span class="s1">'json'</span>
<span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>This creates a table called pos that points to events inside the pos Kafka topic. These events are in JSON format and has the five attributes we introduced previously. In addition to these attributes, it defines an event time field which is computed from the transaction timestamp (tstx) and defines a watermark of 10 seconds. The table uses the Flink Kafka connector and connect to the cluster running in edge2ai-1.dim.local:9092.</p>

<p>Similiarly, we need to create stores and product tables before using them in Flink SQL.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">stores</span> <span class="p">(</span>
   <span class="n">idstore</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">namestore</span> <span class="n">STRING</span><span class="p">,</span>
   <span class="n">city</span> <span class="n">STRING</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
   <span class="s1">'connector.type'</span> <span class="o">=</span> <span class="s1">'kafka'</span><span class="p">,</span>
   <span class="s1">'connector.version'</span> <span class="o">=</span> <span class="s1">'universal'</span><span class="p">,</span>
   <span class="s1">'connector.topic'</span> <span class="o">=</span> <span class="s1">'stores'</span><span class="p">,</span>
   <span class="s1">'connector.startup-mode'</span> <span class="o">=</span> <span class="s1">'earliest-offset'</span><span class="p">,</span>
   <span class="s1">'connector.properties.bootstrap.servers'</span> <span class="o">=</span> <span class="s1">'kafka-url:9092'</span><span class="p">,</span>
   <span class="s1">'connector.properties.group.id'</span> <span class="o">=</span> <span class="s1">'FlinkSQLStore'</span><span class="p">,</span>
   <span class="s1">'format.type'</span> <span class="o">=</span> <span class="s1">'json'</span>
<span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">products</span> <span class="p">(</span>
   <span class="n">idproduct</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">nameproduct</span> <span class="n">STRING</span><span class="p">,</span>
   <span class="n">avgsales</span> <span class="n">INT</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
   <span class="s1">'connector.type'</span> <span class="o">=</span> <span class="s1">'kafka'</span><span class="p">,</span>
   <span class="s1">'connector.version'</span> <span class="o">=</span> <span class="s1">'universal'</span><span class="p">,</span>
   <span class="s1">'connector.topic'</span> <span class="o">=</span> <span class="s1">'products'</span><span class="p">,</span>
   <span class="s1">'connector.startup-mode'</span> <span class="o">=</span> <span class="s1">'earliest-offset'</span><span class="p">,</span>
   <span class="s1">'connector.properties.bootstrap.servers'</span> <span class="o">=</span> <span class="s1">'kafka-url:9092'</span><span class="p">,</span>
   <span class="s1">'connector.properties.group.id'</span> <span class="o">=</span> <span class="s1">'FlinkSQLProducts'</span><span class="p">,</span>
   <span class="s1">'format.type'</span> <span class="o">=</span> <span class="s1">'json'</span>
<span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>We are ready to query our tables: SELECT * FROM pos. It’s as easy as querying data in a SQL database. Here’s how this looks like in Zeppelin. Events are continuously consumed from Kafka and printed in the UI. The FlinkSQL job is visible on the Flink dashboard and the Yarn UI.</p>

<iframe width="1120" height="630" src="https://www.youtube.com/embed/FGj5xqkezzQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Zeppelin has a nice feature of simple data visualization embedded in the notebook. We can use it to plot our events grouped by product and store. This is useful for quick exploration only this is applied on the result sets only and not all data or a time window. Real grouping should be done in FlinkSQL later.</p>

<p><img src="/assets/images/1-5.png" alt="photo" /></p>

<h3 id="stream-to-stream-joins-and-enrichment">Stream to Stream Joins and enrichment</h3>

<p>In the previous graph, we can see events grouped per product and store. However, we only have products and store IDs. Not really useful to understand what’s happening. We can enrich the transactions by joining the POS stream with products and stores streams. Using the idproduct and idstore, we can get other metadata such as the product name and the city.</p>

<p>Keep in mind that the POS stream is a high velocity append-only stream, also known as facts table in the Data WareHouse world (DWH). Stores and Products are slowly changing streams, known as dimensions tables in the DWH world. They are also append-only streams, where an update is a new event with an existing ID. Even if streams joins looks similar to tables joins, there are fundamental differences. For instance, if I have several events on product x, which one will I join with a POS event? the newest one? the one with the closest timestamp? To keep this blog simple, I’ll ignore these aspects for now and I will publish a deep dive blog on streams joins in the coming days.</p>

<p>Going to FlinkSQL, here’s how we can join our three streams:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="k">SELECT</span> <span class="n">tstx</span><span class="p">,</span><span class="n">idtx</span><span class="p">,</span> <span class="n">namestore</span><span class="p">,</span> <span class="n">city</span><span class="p">,</span> <span class="n">nameproduct</span><span class="p">,</span> <span class="n">quantity</span> 
<span class="k">FROM</span> 
   <span class="n">pos</span> <span class="k">AS</span> <span class="n">po</span><span class="p">,</span> 
   <span class="n">stores</span> <span class="k">AS</span> <span class="n">s</span><span class="p">,</span>
   <span class="n">products</span> <span class="k">AS</span> <span class="n">pr</span>
<span class="k">WHERE</span> <span class="n">po</span><span class="p">.</span><span class="n">idstore</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">idstore</span> <span class="k">AND</span> <span class="n">po</span><span class="p">.</span><span class="n">idproduct</span> <span class="o">=</span> <span class="n">pr</span><span class="p">.</span><span class="n">idproduct</span><span class="p">;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Using the join with Zeppelin graphs, we can see how fast our product are sold in every city. The following video show the execution of the query.</p>

<iframe width="1120" height="400" src="https://www.youtube.com/embed/ypAYshAE9vA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h3 id="detect-products-running-out-fast">Detect products running out fast</h3>

<p>Now that we have a better understanding of our data, we can look for the products sale pattern and compare them to historical data. We can not have someone monitor the dashboard all the time, we would like to generate alerts instead.</p>

<p>Remember, in our products table, we have a column, avgsales, that tells us the average quantity we usually sell for every product in every store at a given time scale (4 hours for instance). For demo purposes, we will consider a very short time scale (15 seconds) to accelerate things. So how can we detect that a product is being sold fast?</p>

<p>First, we need to aggregate our POS events on time windows of 15 seconds. For each window, we would like to compute the sum of sold quantity. We would like to do so per store also, hence grouping by store as well. The query looks like the following. Note that the query introduces two new columns, starttime and endtime which represent the time window start and end respectively.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span> <span class="n">starttime</span><span class="p">,</span> <span class="n">TUMBLE_END</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span> <span class="n">endtime</span><span class="p">,</span> <span class="n">idstore</span><span class="p">,</span> <span class="n">idproduct</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">quantity</span><span class="p">)</span> <span class="k">as</span> <span class="k">aggregate</span>
<span class="k">FROM</span> <span class="n">pos</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">idproduct</span><span class="p">,</span><span class="n">idstore</span><span class="p">,</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> <span class="k">SECOND</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Once we have the aggregates stream, we would like to join it with stores and products streams to get the other fields such as avgsales. We would like to compare the computed aggregate quantity, aggregate, with the hostorical avgsales. This gives us the complete query:</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="k">SELECT</span> <span class="n">starttime</span><span class="p">,</span> <span class="n">endtime</span><span class="p">,</span> <span class="n">nameproduct</span><span class="p">,</span> <span class="k">aggregate</span><span class="p">,</span> <span class="n">avgsales</span><span class="p">,</span> <span class="n">namestore</span><span class="p">,</span> <span class="n">city</span> 
<span class="k">FROM</span>
  <span class="p">(</span>
    <span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'30'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span> <span class="n">starttime</span><span class="p">,</span>     
    <span class="n">TUMBLE_END</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'30'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span> <span class="n">endtime</span><span class="p">,</span> <span class="n">idstore</span><span class="p">,</span>   
    <span class="n">idproduct</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">quantity</span><span class="p">)</span> <span class="k">as</span> <span class="k">aggregate</span>
    <span class="k">FROM</span> <span class="n">pos</span>
    <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">idproduct</span><span class="p">,</span><span class="n">idstore</span><span class="p">,</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'30'</span> <span class="k">SECOND</span><span class="p">)</span> 
  <span class="p">)</span> <span class="k">AS</span> <span class="n">a</span><span class="p">,</span>
  <span class="n">products</span> <span class="k">as</span> <span class="n">p</span><span class="p">,</span>
  <span class="n">stores</span> <span class="k">as</span> <span class="n">s</span>
<span class="k">WHERE</span> <span class="k">aggregate</span> <span class="o">&gt;</span> <span class="n">avgsales</span> <span class="k">AND</span> <span class="n">a</span><span class="p">.</span><span class="n">idproduct</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">idproduct</span> <span class="k">AND</span> <span class="n">a</span><span class="p">.</span><span class="n">idstore</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">idstore</span><span class="p">;</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>The following video shows the execution of the query in Zeppelin and the query plan generated in the Flink dashboard. We can observe that hand sanitiser is getting buyed faster than usual in all cities.</p>

<iframe width="1120" height="630" src="https://www.youtube.com/embed/E1IGuuhc-3E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="creating-a-new-alerts-stream">Creating a new alerts stream</h2>
<p>Now that we are happy with our data processing and exploration, we need to create a new stream of alerts. This stream can be used to send push notification to a store manager through a mobile app. Upon receiving this notification, the store manager can ask an employee to refill the shelf of a particular product in priority. This is really important in crisis times where the number of employee can get reduced. This will help proactively manage local activities to avoid having empty shelfs, which reduce the anxiety and the urge of buying a product that may become unavailable.</p>

<p>FlinkSQL can be used to create new Kafka Streams as well. We have to create a new table as we did previously.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">alerts</span> <span class="p">(</span>
   <span class="n">starttime</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
   <span class="n">endtime</span> <span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
   <span class="n">nameproduct</span> <span class="n">STRING</span><span class="p">,</span>
   <span class="k">aggregate</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">avgsales</span> <span class="n">INT</span><span class="p">,</span>
   <span class="n">namestore</span> <span class="n">STRING</span><span class="p">,</span>
   <span class="n">city</span> <span class="n">STRING</span>
<span class="p">)</span> <span class="k">WITH</span> <span class="p">(</span>
   <span class="s1">'connector.type'</span> <span class="o">=</span> <span class="s1">'kafka'</span><span class="p">,</span>
   <span class="s1">'connector.version'</span> <span class="o">=</span> <span class="s1">'universal'</span><span class="p">,</span>
   <span class="s1">'connector.topic'</span> <span class="o">=</span> <span class="s1">'alerts'</span><span class="p">,</span>
   <span class="s1">'connector.startup-mode'</span> <span class="o">=</span> <span class="s1">'latest-offset'</span><span class="p">,</span>
   <span class="s1">'connector.properties.bootstrap.servers'</span> <span class="o">=</span> <span class="s1">'kafka-url:9092'</span><span class="p">,</span>
   <span class="s1">'connector.properties.group.id'</span> <span class="o">=</span> <span class="s1">'FlinkSQLAlerting'</span><span class="p">,</span>
   <span class="s1">'format.type'</span> <span class="o">=</span> <span class="s1">'json'</span>
<span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Then, we can embed our previous aggregation and alerting query into an insert into statement.</p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">alerts</span>
   <span class="k">SELECT</span> <span class="n">starttime</span><span class="p">,</span> <span class="n">endtime</span><span class="p">,</span> <span class="n">nameproduct</span><span class="p">,</span> <span class="k">aggregate</span><span class="p">,</span> <span class="n">avgsales</span><span class="p">,</span>   
          <span class="n">namestore</span><span class="p">,</span> <span class="n">city</span> 
   <span class="k">FROM</span>
     <span class="p">(</span>
     <span class="k">SELECT</span> <span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span>    
        <span class="n">starttime</span><span class="p">,</span> <span class="n">TUMBLE_END</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> <span class="k">SECOND</span><span class="p">)</span> <span class="k">as</span> 
        <span class="n">endtime</span><span class="p">,</span> <span class="n">idstore</span><span class="p">,</span> <span class="n">idproduct</span><span class="p">,</span> <span class="k">SUM</span><span class="p">(</span><span class="n">quantity</span><span class="p">)</span> <span class="k">as</span> <span class="k">aggregate</span>
     <span class="k">FROM</span> <span class="n">pos</span>
     <span class="k">GROUP</span> <span class="k">BY</span> <span class="n">idproduct</span><span class="p">,</span><span class="n">idstore</span><span class="p">,</span> <span class="n">TUMBLE</span><span class="p">(</span><span class="n">timetx</span><span class="p">,</span> <span class="n">INTERVAL</span> <span class="s1">'15'</span> 
     <span class="k">SECOND</span><span class="p">)</span> <span class="p">)</span> <span class="k">AS</span> <span class="n">a</span><span class="p">,</span>
     <span class="n">products</span> <span class="k">as</span> <span class="n">p</span><span class="p">,</span>
     <span class="n">stores</span> <span class="k">as</span> <span class="n">s</span>
   <span class="k">WHERE</span> <span class="k">aggregate</span> <span class="o">&gt;</span> <span class="n">avgsales</span> <span class="k">AND</span> <span class="n">a</span><span class="p">.</span><span class="n">idproduct</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">idproduct</span> <span class="k">AND</span> 
   <span class="n">a</span><span class="p">.</span><span class="n">idstore</span> <span class="o">=</span> <span class="n">s</span><span class="p">.</span><span class="n">idstore</span><span class="p">;</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>With this, all generated alerts are send into the alerts Kafka topic as we can see in SMM. From Kafka, we can have a NiFi, KStreams or Java apps subscribing to these alert events and pushing them into our store managers.</p>

<iframe width="1120" height="630" src="https://www.youtube.com/embed/9kkikdoogi4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="conclusions">Conclusions</h2>

<p>In this blog, we explained how a streaming platform can enable any supply chain to get real time insights. These insights are a game changer in a crisis situation where demand is huge and uncertainty increasing. This is exactly what we are living nowadays with the Covid19 crisis.</p>

<p>We also showed how we can build an advanced event-driven alerting system with no line of code using tools like Apache NiFi, Apache Flink and Apache Zeppelin. Flink provides advanced streams operations like streaming joins and windowing with a simple SQL API. Building an advanced real-time supply chain system become accessible to everyone. Event Streaming platforms like CDF package all these tools into a unified stack that’s easy to deploy and use.</p>

<p>In a future blog, I’ll cover streams join types in Flink and Flink SQL. If you are interested in a deeper dive on these topics, come back to this blog in few days.</p>

<p>Thanks for reading this far. As always, feedback and suggestions are welcome.</p>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2020-04-12">12 Apr 2020</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Event-Driven">Event Driven</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Flink">Flink</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#SQL">SQL</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Streaming">Streaming</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Use-case">Use case</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->


</div>


    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/categories#Streaming">Streaming (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Event-Driven">Event Driven (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Use-case">Use case (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Flink">Flink (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#SQL">SQL (1)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2020 Data Crafts 
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//.disqus.com/count.js"></script>


</body>
</html>
